{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import read_cifar10 as cf10\n",
    "\n",
    "#@read_data.restartable\n",
    "def cifar10_dataset_generator(dataset_name, batch_size, restrict_size=1000):\n",
    "    assert dataset_name in ['train', 'test']\n",
    "    assert batch_size > 0 or batch_size == -1  # -1 for entire dataset\n",
    "    \n",
    "    X_all_unrestricted, y_all = (cf10.load_training_data() if dataset_name == 'train'\n",
    "                                 else cf10.load_test_data())\n",
    "    \n",
    "    actual_restrict_size = restrict_size if dataset_name == 'train' else int(1e10)\n",
    "    X_all = X_all_unrestricted[:actual_restrict_size]\n",
    "    data_len = X_all.shape[0]\n",
    "    batch_size = batch_size if batch_size > 0 else data_len\n",
    "    \n",
    "    X_all_padded = np.concatenate([X_all, X_all[:batch_size]], axis=0)\n",
    "    y_all_padded = np.concatenate([y_all, y_all[:batch_size]], axis=0)\n",
    "    \n",
    "    for slice_i in range(math.ceil(data_len / batch_size)):\n",
    "        idx = slice_i * batch_size\n",
    "        #X_batch = X_all_padded[idx:idx + batch_size]\n",
    "        X_batch = X_all_padded[idx:idx + batch_size]*255  # bugfix: thanks Zezhou Sun!\n",
    "        y_batch = np.ravel(y_all_padded[idx:idx + batch_size])\n",
    "        yield X_batch.astype(np.uint8), y_batch.astype(np.uint8)\n",
    "\n",
    "cifar10_dataset_generators = {\n",
    "    'train': cifar10_dataset_generator('train', 1000),\n",
    "    'test': cifar10_dataset_generator('test', -1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load cifar-10 data\n",
    "cf10_tr=cf10.load_training_data()\n",
    "cf10_tr_img=cf10_tr[0]\n",
    "cf10_tr_label = cf10_tr[1]\n",
    "\n",
    "cf10_test=cf10.load_test_data()\n",
    "cf10_test_img=cf10_test[0]\n",
    "cf10_test_label = cf10_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "def img2block(im):\n",
    "    #lion[:2816,:4224,:]\n",
    "    #skimage.io.imshow(lion)\n",
    "    #skimage.io.show()\n",
    "    \n",
    "    im = im.astype(np.float32)\n",
    "    row,col,color = im.shape\n",
    "    im_bl=np.zeros((int(row*col/1024),32,32,3)).astype(np.float32)\n",
    "    count=0\n",
    "    for i in range(0,row-row%32,32):\n",
    "        for j in range(0,col-col%32,32):\n",
    "            im_bl[count,:,:,:]=im[i:i+32,j:j+32,:]\n",
    "            count = count +1\n",
    "    im_bl=im_bl/255.\n",
    "    return im_bl\n",
    "\n",
    "def block2img(img_blocks,img_size):\n",
    "    \n",
    "    row,col = img_size\n",
    "    img=np.zeros((row,col,3)).astype(np.float32)\n",
    "    n,k,l,c=img_blocks.shape\n",
    "                 \n",
    "    for i in range(0,int(row/k)):\n",
    "        for j in range(0,int(col/k)):\n",
    "            img[i*k:(i+1)*k,j*l:(j+1)*l,:]=img_blocks[int(i*col/k+j),:,:,:]\n",
    "    return img\n",
    "\n",
    "#Get the patches of lena image\n",
    "lena_img = skimage.io.imread('../test_img/lena512color.tiff')\n",
    "lena_32=img2block(lena_img)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for converting a double to uint8\n",
    "def convert2uint8(img):\n",
    "    img[img>255]=255\n",
    "    img[img<0]=0\n",
    "    return img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create the inputs in the desired format\n",
    "x_tr = cf10_tr_img.astype(np.float32)#*255.\n",
    "x_test = cf10_test_img.astype(np.float32)#*255.\n",
    "x_test=x_test[:200,:,:,:]\n",
    "img = skimage.io.imread('../test_img/lena512color.tiff')\n",
    "img_32=img2block(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn_autoencoder(x_,kernels1=[5,7],kernels2=[7,5],filters1=[16,128],filters2=[128,3],pool_size=[1,2,2,1],name='autoencoder'):\n",
    "    '''\n",
    "    Autoencoder network\n",
    "    \n",
    "    Inputs:\n",
    "    x_ (tf.placeholder) : Input tensor\n",
    "    kernels1 (1D array) : Size of the encoder kernels (assumed square kernels)\n",
    "    kernels2 (1D array) : Size of the decoder kernels (assumed square kernels)\n",
    "    filters1 (1D array) : Number of filters in encoder layers\n",
    "    filters2 (1D array) : Number of filters in decoder layers\n",
    "    pool_size (1D array): Pooling size in each layer. Its length must be equal to len(kernels1)+len(kernels2)\n",
    "                          First len(kernels1) terms will be used as pooling layers of encoder/\n",
    "                          Remainin terms will be used as unpooling layers of decoder\n",
    "                          \n",
    "    Returns:\n",
    "    out_ (tf.placeholder)     : Output of the autoencoder without quantization in the middle\n",
    "    out_quant (tf.placeholder): Output of the autoencoder with quantization in the middle\n",
    "    '''\n",
    "    with tf.variable_scope(name):\n",
    "        out_=x_\n",
    "        for k in range(len(kernels1)):\n",
    "            conv = tf.layers.conv2d(inputs=out_,\n",
    "                                    filters=filters1[k],\n",
    "                                    kernel_size=[kernels1[k],kernels1[k]],\n",
    "                                    padding=\"same\",\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    name='conv'+str(k))\n",
    "            pool_now=pool_size[k]\n",
    "            if(pool_now==1):\n",
    "                out_=conv\n",
    "            else:\n",
    "                out_ = tf.layers.max_pooling2d(inputs=conv, \n",
    "                                               pool_size=[pool_now,pool_now], \n",
    "                                               strides=pool_now,\n",
    "                                               name = 'pool'+str(k))\n",
    "\n",
    "            out_quant=tf.round(out_*255.)/255.\n",
    "\n",
    "        for k in range(len(kernels2)):\n",
    "            with tf.variable_scope(\"deconv\") as var_scope:\n",
    "                pool_now=pool_size[k+len(kernels1)]\n",
    "                if(pool_now==1):\n",
    "                    x_up=out_\n",
    "                    out_ = tf.layers.conv2d(inputs=x_up,\n",
    "                                            filters=filters2[k],\n",
    "                                            kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                            padding=\"same\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            name='deconv'+str(k))\n",
    "                    var_scope.reuse_variables() \n",
    "                    x_quant_up=out_quant\n",
    "                    out_quant = tf.layers.conv2d(inputs=x_quant_up,\n",
    "                                                filters=filters2[k],\n",
    "                                                kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                                padding=\"same\",\n",
    "                                                activation=tf.nn.relu,\n",
    "                                                name='deconv'+str(k))\n",
    "                else:\n",
    "                    sh = out_.get_shape().as_list()\n",
    "                    x_up=tf.image.resize_images(out_,[sh[1]*pool_now,sh[2]*pool_now])\n",
    "                    out_ = tf.layers.conv2d(inputs=x_up,\n",
    "                                            filters=filters2[k],\n",
    "                                            kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                            padding=\"same\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            name='deconv'+str(k))\n",
    "                    var_scope.reuse_variables() \n",
    "                    x_quant_up=tf.image.resize_images(out_quant,[sh[1]*pool_now,sh[2]*pool_now])\n",
    "                    out_quant = tf.layers.conv2d(inputs=x_quant_up,\n",
    "                                                filters=filters2[k],\n",
    "                                                kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                                padding=\"same\",\n",
    "                                                activation=tf.nn.relu,\n",
    "                                                name='deconv'+str(k))\n",
    "\n",
    "\n",
    "    return out_,out_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Working\n",
    "def apply_classification_loss_mse_with_rnn(kernels1=[5,7],kernels2=[7,5],\n",
    "                                     filters1=[16,128],filters2=[128,3],\n",
    "                                    pool_size=[2,2],learning_rate=1.,FT=False,depth =3):\n",
    "    '''\n",
    "    MSE based autoencoder optimizer.\n",
    "    \n",
    "    Inputs:\n",
    "    kernels1 (1D array) : Size of the encoder kernels (assumed square kernels)\n",
    "    kernels2 (1D array) : Size of the decoder kernels (assumed square kernels)\n",
    "    filters1 (1D array) : Number of filters in encoder layers\n",
    "    filters2 (1D array) : Number of filters in decoder layers\n",
    "    pool_size (1D array): Pooling size in each layer. Its length must be equal to len(kernels1)+len(kernels2)\n",
    "                          First len(kernels1) terms will be used as pooling layers of encoder/\n",
    "                          Remainin terms will be used as unpooling layers of decoder\n",
    "    learning_rate(float): Learning rate of the optimizer\n",
    "    FT (boolean)        : Boolean value for fine-tuning operation on decoder weights\n",
    "    depth(integer)      \n",
    "    \n",
    "    Returns:\n",
    "    model_dict          : Dictionary of the required output files\n",
    "    '''\n",
    "    with tf.Graph().as_default() as g:\n",
    "        with tf.device(\"/gpu:0\"):  # use gpu:0 if on GPU\n",
    "            x_ = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "            \n",
    "            \n",
    "            (x_out2,x_out_quant)=cnn_autoencoder(x_,pool_size=pool_size,kernels1=kernels1,filters1=filters1,\n",
    "                                kernels2=kernels2,filters2=filters2,name='filter0')\n",
    "            x_out1=x_\n",
    "            mse_loss1=tf.reduce_mean(tf.subtract(x_out1,x_out2)**2)\n",
    "            for k in range(1,depth):\n",
    "                (x_out3,x_out_quant)=cnn_autoencoder(x_out1-x_out2,pool_size=pool_size,kernels1=kernels1,filters1=filters1,\n",
    "                                kernels2=kernels2,filters2=filters2,name='filter'+str(k))\n",
    "                mse_loss1=tf.add(mse_loss1,tf.reduce_mean(tf.subtract(x_out1,tf.add(x_out2,x_out3))**2))\n",
    "                x_out1=x_out2\n",
    "                x_out2=x_out3\n",
    "            x_out3=x_out2\n",
    "            #y_dict = dict(labels=y_, logits=y_logits)\n",
    "            #losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict)\n",
    "            #cross_entropy_loss = tf.reduce_mean(losses)\n",
    "            #mse_loss1=tf.reduce_mean(tf.subtract(x_,x_out)**2)\n",
    "            #a=tf.pad(tf.subtract(x_,x_out),[[0,0],[16,16],[16,16],[0,0]],'CONSTANT')\n",
    "\n",
    "            #mse_loss1=tf.reduce_mean(tf.nn.conv2d(a,h3,strides=[1,1,1,1],padding=\"VALID\")**2)\n",
    "            mse_loss2=tf.reduce_mean(tf.subtract(x_,x_out3)**2)\n",
    "            trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            if(FT):\n",
    "                with tf.variable_scope('deconv', reuse=True) as vs:\n",
    "                    var_list=[v for v in tf.global_variables() if v.name.startswith(vs.name)]\n",
    "                train_op = trainer.minimize(mse_loss1,var_list=var_list)\n",
    "            else:\n",
    "                train_op = trainer.minimize(mse_loss1)\n",
    "\n",
    "            #y_pred = tf.argmax(tf.nn.softmax(y_logits), dimension=1)\n",
    "            #correct_prediction = tf.equal(tf.cast(y_pred, tf.int32), y_)\n",
    "            #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    model_dict = {'graph': g, 'inputs': x_,'outputs':x_out_quant, 'train_op': train_op, 'loss1': mse_loss1,'loss2': mse_loss2}\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model_dict, dataset_generators, train_every=100, test_every=200, load=False,\n",
    "                learning_rate=1.,fname='cifar10_recon',outname='/tmp/cnn_autoencoder',ftname='/tmp/cnn_autoencoder'):\n",
    "    '''\n",
    "    Inputs:\n",
    "    model_dict: Output of apply_classification_loss_mse\n",
    "    x_tr      : Training images\n",
    "    x_test    : Test Images\n",
    "    x_32      : 32x32 patches of a big image\n",
    "    load      : Boolean for loading the weights from pre-trained network\n",
    "    fname     : Directory to save outputs\n",
    "    outname   : Directory to save (load=False) or load (load=True) weights\n",
    "    ftname    : Directory to save new weights when load+True\n",
    "    '''\n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ### WORK ON IT NOT TOO HARD\n",
    "        saver=tf.train.Saver()\n",
    "        if(load):\n",
    "            saver.restore(sess, outname)\n",
    "            print(\"Model loaded\")\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        ids=[i for i in range(100)]\n",
    "        for iter_i in range(10000):\n",
    "            batch_xs = x_tr[ids,:,:,:] \n",
    "            ids=[(ids[0]+100+i)%x_tr.shape[0] for i in range(100)]\n",
    "            sess.run(model_dict['train_op'], feed_dict={model_dict['inputs']: batch_xs})\n",
    "            \n",
    "            # test trained model\n",
    "            if iter_i % train_every == 0:\n",
    "                tf_feed_dict = {model_dict['inputs']: batch_xs}\n",
    "                loss_val = sess.run(model_dict['loss1'], feed_dict={model_dict['inputs']: batch_xs})\n",
    "                print('iteration %d\\t train mse: %.3E\\t'%(iter_i,loss_val))\n",
    "                if iter_i % test_every == 0:\n",
    "                    #tf_feed_dict = {x_: x_test}\n",
    "                    loss_val1 = sess.run(model_dict['loss1'], feed_dict={model_dict['inputs']: x_test})\n",
    "                    loss_val2 = sess.run(model_dict['loss2'], feed_dict={model_dict['inputs']: x_test})\n",
    "                    print('iteration %d\\t TEST MSE: %.3E\\t TEST MSE(Quantized): %.3E\\t'%(iter_i,loss_val1,loss_val2))\n",
    "                    \n",
    "                    \n",
    "                    lena_block=sess.run(model_dict['outputs'], \n",
    "                                       feed_dict={model_dict['inputs']:img_32})\n",
    "                    x_from_test=sess.run(model_dict['outputs'], \n",
    "                                         feed_dict={model_dict['inputs']:x_test[:5,:,:,:].reshape([-1,32,32,3])})\n",
    "                    \n",
    "                    lena_recon=block2img(lena_block,(512,512))\n",
    "                    lena_recon = convert2uint8(lena_recon*255.)\n",
    "                    skimage.io.imsave('../'+fname+'/lena4_'+str(int(iter_i/test_every))+'.tiff',lena_recon)\n",
    "\n",
    "                    for i in range(2):\n",
    "                        img_recon=convert2uint8((255*x_from_test[i,:,:,:]).reshape([32,32,3])).astype(np.uint8)\n",
    "                        skimage.io.imsave('../'+fname+'/test'+str(i)+'_'+str(int(iter_i/test_every))+'.tiff',img_recon)\n",
    "                        \n",
    "        saver = tf.train.Saver()\n",
    "        if(load):\n",
    "            outname=ftname\n",
    "        save_path = saver.save(sess, outname)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        return saver\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CNN-RNN-AE with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\t train mse: 4.982E-01\t\n",
      "iteration 0\t TEST MSE: 5.656E-01\t TEST MSE(Quantized): 2.967E-01\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/lena4_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/test0_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/test1_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100\t train mse: 2.486E-01\t\n"
     ]
    }
   ],
   "source": [
    "#YOU NEED TO CREATE A FOLDER NAMED 'cifar10_recon3' BEFORE RUNNING THAT CODE\n",
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse_with_rnn(kernels1=[5,7,9,9],kernels2=[9,7,7,5],\n",
    "                                         filters1=[128,64,16,4],filters2=[8,8,3,3],\n",
    "                                         pool_size=[1,2,2,1,1,2,2,1],learning_rate=7e-5)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=2000,load=False,\n",
    "                    fname='cifar10_recon2',outname='/tmp/cnnx4_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/cnn_autoencoderx16\n",
      "Model loaded\n",
      "iteration 0\t train mse: 6.739E-04\t\n",
      "iteration 0\t TEST MSE: 3.041E-03\t TEST MSE(Quantized): 3.042E-03\t\n",
      "iteration 100\t train mse: 4.539E-04\t\n",
      "iteration 200\t train mse: 5.587E-04\t\n",
      "iteration 300\t train mse: 5.086E-04\t\n",
      "iteration 400\t train mse: 6.164E-04\t\n",
      "iteration 500\t train mse: 5.478E-04\t\n",
      "iteration 600\t train mse: 6.552E-04\t\n",
      "iteration 700\t train mse: 5.413E-04\t\n",
      "iteration 800\t train mse: 5.983E-04\t\n",
      "iteration 900\t train mse: 4.947E-04\t\n",
      "iteration 1000\t train mse: 5.851E-04\t\n",
      "iteration 1000\t TEST MSE: 2.817E-03\t TEST MSE(Quantized): 2.818E-03\t\n",
      "iteration 1100\t train mse: 5.438E-04\t\n",
      "iteration 1200\t train mse: 4.355E-04\t\n",
      "iteration 1300\t train mse: 6.725E-04\t\n",
      "iteration 1400\t train mse: 4.570E-04\t\n",
      "iteration 1500\t train mse: 6.676E-04\t\n",
      "iteration 1600\t train mse: 4.150E-04\t\n",
      "iteration 1700\t train mse: 6.416E-04\t\n",
      "iteration 1800\t train mse: 3.885E-04\t\n",
      "iteration 1900\t train mse: 4.092E-04\t\n",
      "iteration 2000\t train mse: 4.575E-04\t\n",
      "iteration 2000\t TEST MSE: 2.822E-03\t TEST MSE(Quantized): 2.823E-03\t\n",
      "iteration 2100\t train mse: 5.962E-04\t\n",
      "iteration 2200\t train mse: 4.486E-04\t\n",
      "iteration 2300\t train mse: 8.340E-04\t\n",
      "iteration 2400\t train mse: 5.678E-04\t\n",
      "iteration 2500\t train mse: 5.543E-04\t\n",
      "iteration 2600\t train mse: 6.273E-04\t\n",
      "iteration 2700\t train mse: 4.872E-04\t\n",
      "iteration 2800\t train mse: 4.873E-04\t\n",
      "iteration 2900\t train mse: 5.519E-04\t\n",
      "iteration 3000\t train mse: 5.739E-04\t\n",
      "iteration 3000\t TEST MSE: 2.927E-03\t TEST MSE(Quantized): 2.928E-03\t\n",
      "iteration 3100\t train mse: 5.312E-04\t\n",
      "iteration 3200\t train mse: 6.727E-04\t\n",
      "iteration 3300\t train mse: 5.550E-04\t\n",
      "iteration 3400\t train mse: 5.352E-04\t\n",
      "iteration 3500\t train mse: 5.614E-04\t\n",
      "iteration 3600\t train mse: 5.193E-04\t\n",
      "iteration 3700\t train mse: 6.279E-04\t\n",
      "iteration 3800\t train mse: 5.338E-04\t\n",
      "iteration 3900\t train mse: 5.728E-04\t\n",
      "iteration 4000\t train mse: 5.630E-04\t\n",
      "iteration 4000\t TEST MSE: 2.837E-03\t TEST MSE(Quantized): 2.837E-03\t\n",
      "iteration 4100\t train mse: 4.587E-04\t\n",
      "iteration 4200\t train mse: 4.720E-04\t\n",
      "iteration 4300\t train mse: 4.915E-04\t\n",
      "iteration 4400\t train mse: 6.065E-04\t\n",
      "iteration 4500\t train mse: 3.990E-04\t\n",
      "iteration 4600\t train mse: 6.113E-04\t\n",
      "iteration 4700\t train mse: 4.705E-04\t\n",
      "iteration 4800\t train mse: 4.384E-04\t\n",
      "iteration 4900\t train mse: 4.449E-04\t\n",
      "iteration 5000\t train mse: 4.213E-04\t\n",
      "iteration 5000\t TEST MSE: 2.789E-03\t TEST MSE(Quantized): 2.790E-03\t\n",
      "iteration 5100\t train mse: 4.870E-04\t\n",
      "iteration 5200\t train mse: 3.851E-04\t\n",
      "iteration 5300\t train mse: 3.940E-04\t\n",
      "iteration 5400\t train mse: 4.420E-04\t\n",
      "iteration 5500\t train mse: 5.150E-04\t\n",
      "iteration 5600\t train mse: 4.750E-04\t\n",
      "iteration 5700\t train mse: 5.714E-04\t\n",
      "iteration 5800\t train mse: 3.607E-04\t\n",
      "iteration 5900\t train mse: 4.098E-04\t\n",
      "iteration 6000\t train mse: 4.628E-04\t\n",
      "iteration 6000\t TEST MSE: 2.751E-03\t TEST MSE(Quantized): 2.752E-03\t\n",
      "iteration 6100\t train mse: 4.810E-04\t\n",
      "iteration 6200\t train mse: 5.323E-04\t\n",
      "iteration 6300\t train mse: 4.888E-04\t\n",
      "iteration 6400\t train mse: 4.421E-04\t\n",
      "iteration 6500\t train mse: 4.526E-04\t\n",
      "iteration 6600\t train mse: 4.650E-04\t\n",
      "iteration 6700\t train mse: 5.213E-04\t\n",
      "iteration 6800\t train mse: 4.586E-04\t\n",
      "iteration 6900\t train mse: 4.311E-04\t\n",
      "iteration 7000\t train mse: 4.450E-04\t\n",
      "iteration 7000\t TEST MSE: 2.817E-03\t TEST MSE(Quantized): 2.817E-03\t\n",
      "iteration 7100\t train mse: 4.793E-04\t\n",
      "iteration 7200\t train mse: 4.231E-04\t\n",
      "iteration 7300\t train mse: 5.076E-04\t\n",
      "iteration 7400\t train mse: 3.912E-04\t\n",
      "iteration 7500\t train mse: 4.008E-04\t\n",
      "iteration 7600\t train mse: 5.361E-04\t\n",
      "iteration 7700\t train mse: 4.648E-04\t\n",
      "iteration 7800\t train mse: 4.881E-04\t\n",
      "iteration 7900\t train mse: 3.269E-04\t\n",
      "iteration 8000\t train mse: 2.656E-04\t\n",
      "iteration 8000\t TEST MSE: 2.675E-03\t TEST MSE(Quantized): 2.676E-03\t\n",
      "iteration 8100\t train mse: 3.662E-04\t\n",
      "iteration 8200\t train mse: 4.107E-04\t\n",
      "iteration 8300\t train mse: 3.890E-04\t\n",
      "iteration 8400\t train mse: 4.336E-04\t\n",
      "iteration 8500\t train mse: 4.120E-04\t\n",
      "iteration 8600\t train mse: 4.366E-04\t\n",
      "iteration 8700\t train mse: 4.158E-04\t\n",
      "iteration 8800\t train mse: 4.469E-04\t\n",
      "iteration 8900\t train mse: 3.465E-04\t\n",
      "iteration 9000\t train mse: 4.593E-04\t\n",
      "iteration 9000\t TEST MSE: 2.874E-03\t TEST MSE(Quantized): 2.875E-03\t\n",
      "iteration 9100\t train mse: 5.490E-04\t\n",
      "iteration 9200\t train mse: 6.836E-04\t\n",
      "iteration 9300\t train mse: 3.567E-04\t\n",
      "iteration 9400\t train mse: 5.313E-04\t\n",
      "iteration 9500\t train mse: 5.299E-04\t\n",
      "iteration 9600\t train mse: 3.578E-04\t\n",
      "iteration 9700\t train mse: 5.552E-04\t\n",
      "iteration 9800\t train mse: 4.117E-04\t\n",
      "iteration 9900\t train mse: 3.756E-04\t\n",
      "Model saved in file: /tmp/cnn_autoencoder_lionx8\n"
     ]
    }
   ],
   "source": [
    "img = skimage.io.imread('../test_img/lion.tiff')\n",
    "img_32=img2block(img)\n",
    "\n",
    "tmp=x_tr.copy()\n",
    "x_tr=img_32.copy()\n",
    "idx=np.random.permutation(x_tr.shape[0])\n",
    "x_tr=x_tr[idx,:,:,:]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse(kernels1=[5,7,9],kernels2=[5,5],\n",
    "                                     filters1=[16,64,128],filters2=[16,3],\n",
    "                                     pool_size=[1,2,2,2,2],learning_rate=0.0001,FT=False)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=1000,load=True,\n",
    "                    fname='cifar10_recon0',outname='/tmp/cnn_autoencoderx16',ftname='/tmp/cnn_autoencoder_lionx8')\n",
    "\n",
    "x_tr=tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\t train mse: 4.048E-01\t\n",
      "iteration 0\t TEST MSE: 4.485E-01\t TEST MSE(Quantized): 2.818E-01\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/test0_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/test1_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100\t train mse: 3.096E-02\t\n",
      "iteration 200\t train mse: 2.295E-02\t\n",
      "iteration 300\t train mse: 2.119E-02\t\n",
      "iteration 400\t train mse: 1.881E-02\t\n",
      "iteration 500\t train mse: 1.822E-02\t\n",
      "iteration 600\t train mse: 1.356E-02\t\n",
      "iteration 700\t train mse: 1.337E-02\t\n",
      "iteration 800\t train mse: 1.444E-02\t\n",
      "iteration 900\t train mse: 1.460E-02\t\n",
      "iteration 1000\t train mse: 1.495E-02\t\n",
      "iteration 1000\t TEST MSE: 1.368E-02\t TEST MSE(Quantized): 9.144E-03\t\n",
      "iteration 1100\t train mse: 1.067E-02\t\n",
      "iteration 1200\t train mse: 1.047E-02\t\n",
      "iteration 1300\t train mse: 1.190E-02\t\n",
      "iteration 1400\t train mse: 1.128E-02\t\n",
      "iteration 1500\t train mse: 1.116E-02\t\n",
      "iteration 1600\t train mse: 9.533E-03\t\n",
      "iteration 1700\t train mse: 9.255E-03\t\n",
      "iteration 1800\t train mse: 1.125E-02\t\n",
      "iteration 1900\t train mse: 1.003E-02\t\n",
      "iteration 2000\t train mse: 1.007E-02\t\n",
      "iteration 2000\t TEST MSE: 9.124E-03\t TEST MSE(Quantized): 6.320E-03\t\n",
      "iteration 2100\t train mse: 8.347E-03\t\n",
      "iteration 2200\t train mse: 8.839E-03\t\n",
      "iteration 2300\t train mse: 9.396E-03\t\n",
      "iteration 2400\t train mse: 9.037E-03\t\n",
      "iteration 2500\t train mse: 9.269E-03\t\n",
      "iteration 2600\t train mse: 9.957E-02\t\n",
      "iteration 2700\t train mse: 1.302E-02\t\n",
      "iteration 2800\t train mse: 1.137E-02\t\n",
      "iteration 2900\t train mse: 1.056E-02\t\n",
      "iteration 3000\t train mse: 1.050E-02\t\n",
      "iteration 3000\t TEST MSE: 9.443E-03\t TEST MSE(Quantized): 7.999E-03\t\n",
      "iteration 3100\t train mse: 8.562E-03\t\n",
      "iteration 3200\t train mse: 8.348E-03\t\n",
      "iteration 3300\t train mse: 9.044E-03\t\n",
      "iteration 3400\t train mse: 8.983E-03\t\n",
      "iteration 3500\t train mse: 9.298E-03\t\n",
      "iteration 3600\t train mse: 7.760E-03\t\n",
      "iteration 3700\t train mse: 7.612E-03\t\n",
      "iteration 3800\t train mse: 8.391E-03\t\n",
      "iteration 3900\t train mse: 8.273E-03\t\n",
      "iteration 4000\t train mse: 8.517E-03\t\n",
      "iteration 4000\t TEST MSE: 7.783E-03\t TEST MSE(Quantized): 5.983E-03\t\n",
      "iteration 4100\t train mse: 7.130E-03\t\n",
      "iteration 4200\t train mse: 7.870E-03\t\n",
      "iteration 4300\t train mse: 8.705E-03\t\n",
      "iteration 4400\t train mse: 8.226E-03\t\n",
      "iteration 4500\t train mse: 8.387E-03\t\n",
      "iteration 4600\t train mse: 7.065E-03\t\n",
      "iteration 4700\t train mse: 6.856E-03\t\n",
      "iteration 4800\t train mse: 7.753E-03\t\n",
      "iteration 4900\t train mse: 7.487E-03\t\n",
      "iteration 5000\t train mse: 7.662E-03\t\n",
      "iteration 5000\t TEST MSE: 7.038E-03\t TEST MSE(Quantized): 6.012E-03\t\n",
      "iteration 5100\t train mse: 6.476E-03\t\n",
      "iteration 5200\t train mse: 6.865E-03\t\n",
      "iteration 5300\t train mse: 7.811E-03\t\n",
      "iteration 5400\t train mse: 7.047E-03\t\n",
      "iteration 5500\t train mse: 7.213E-03\t\n",
      "iteration 5600\t train mse: 6.289E-03\t\n",
      "iteration 5700\t train mse: 6.325E-03\t\n",
      "iteration 5800\t train mse: 6.768E-03\t\n",
      "iteration 5900\t train mse: 6.689E-03\t\n",
      "iteration 6000\t train mse: 6.956E-03\t\n",
      "iteration 6000\t TEST MSE: 6.420E-03\t TEST MSE(Quantized): 5.033E-03\t\n",
      "iteration 6100\t train mse: 5.899E-03\t\n",
      "iteration 6200\t train mse: 5.796E-03\t\n",
      "iteration 6300\t train mse: 6.727E-03\t\n",
      "iteration 6400\t train mse: 6.557E-03\t\n",
      "iteration 6500\t train mse: 6.651E-03\t\n",
      "iteration 6600\t train mse: 5.793E-03\t\n",
      "iteration 6700\t train mse: 5.465E-03\t\n",
      "iteration 6800\t train mse: 6.286E-03\t\n",
      "iteration 6900\t train mse: 6.153E-03\t\n",
      "iteration 7000\t train mse: 6.548E-03\t\n",
      "iteration 7000\t TEST MSE: 6.084E-03\t TEST MSE(Quantized): 4.634E-03\t\n",
      "iteration 7100\t train mse: 7.014E-03\t\n",
      "iteration 7200\t train mse: 6.120E-03\t\n",
      "iteration 7300\t train mse: 5.994E-03\t\n",
      "iteration 7400\t train mse: 5.823E-03\t\n",
      "iteration 7500\t train mse: 6.438E-03\t\n",
      "iteration 7600\t train mse: 5.137E-03\t\n",
      "iteration 7700\t train mse: 6.098E-03\t\n",
      "iteration 7800\t train mse: 6.000E-03\t\n",
      "iteration 7900\t train mse: 5.725E-03\t\n",
      "iteration 8000\t train mse: 5.727E-03\t\n",
      "iteration 8000\t TEST MSE: 5.300E-03\t TEST MSE(Quantized): 4.964E-03\t\n",
      "iteration 8100\t train mse: 5.068E-03\t\n",
      "iteration 8200\t train mse: 4.877E-03\t\n",
      "iteration 8300\t train mse: 5.724E-03\t\n",
      "iteration 8400\t train mse: 5.465E-03\t\n",
      "iteration 8500\t train mse: 5.731E-03\t\n",
      "iteration 8600\t train mse: 4.851E-03\t\n",
      "iteration 8700\t train mse: 4.640E-03\t\n",
      "iteration 8800\t train mse: 5.339E-03\t\n",
      "iteration 8900\t train mse: 5.155E-03\t\n",
      "iteration 9000\t train mse: 5.410E-03\t\n",
      "iteration 9000\t TEST MSE: 5.038E-03\t TEST MSE(Quantized): 4.885E-03\t\n",
      "iteration 9100\t train mse: 4.633E-03\t\n",
      "iteration 9200\t train mse: 4.675E-03\t\n",
      "iteration 9300\t train mse: 5.059E-03\t\n",
      "iteration 9400\t train mse: 5.121E-03\t\n",
      "iteration 9500\t train mse: 5.405E-03\t\n",
      "iteration 9600\t train mse: 4.443E-03\t\n",
      "iteration 9700\t train mse: 4.339E-03\t\n",
      "iteration 9800\t train mse: 4.801E-03\t\n",
      "iteration 9900\t train mse: 4.948E-03\t\n",
      "Model saved in file: /tmp/rnn_autoencoderdeepx6\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse_with_error(kernels1=[5,7,9],kernels2=[9,7,5],\n",
    "                                     filters1=[16,64,128],filters2=[64,16,3],\n",
    "                                     pool_size=[1,2,2,2,2,1],learning_rate=0.0001,depth=3)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=1000,load=False,\n",
    "                    fname='cifar10_recon0',outname='/tmp/rnn_autoencoderdeepx6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 6, 3)\n",
      "(11771, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#op = tf.shape(tf.nn.conv2d(tf.random_normal([1,10,10,3]), \n",
    "#             tf.random_normal([10,10,3,1]), \n",
    "#              strides=[1, 1,1, 1], padding='VALID'))\n",
    "op = tf.pad(tf.random_normal([1,3,3,3]),[[0,0],[0,3],[0,3],[0,0]],'CONSTANT')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(op)\n",
    "    print(result.shape)\n",
    "print(lion_32.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/rnn_autoencoderdeepx6\n",
      "Model loaded\n",
      "5\n",
      "1th slice\n",
      "2th slice\n",
      "3th slice\n",
      "4th slice\n",
      "5th slice\n"
     ]
    }
   ],
   "source": [
    "#model_dict=apply_classification_loss_mse(kernels1=[5,7,9],kernels2=[5,5],\n",
    "#                                     filters1=[16,64,128],filters2=[16,3],\n",
    "#                                     pool_size=[1,2,2,2,2],learning_rate=0.0001,FT=False)\n",
    "\n",
    "\n",
    "tfsave ='/tmp/rnn_autoencoderdeepx6'\n",
    "imgpath = '../test_img/lion.tiff'\n",
    "outpath='../test_img/lion_recon2_rnnx8.tiff'\n",
    "with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "#with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    '''\n",
    "    var_list=[]\n",
    "    with tf.variable_scope('conv1',reuse=True):\n",
    "        var_list.append ( tf.get_variable('kernel') )\n",
    "    '''\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tfsave)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    img = skimage.io.imread(imgpath)\n",
    "    [w,l,c]=img.shape\n",
    "    img_32=img2block(img)\n",
    "    img_block = np.zeros(img_32.shape)\n",
    "    \n",
    "    n= np.floor(img_32.shape[0]/2000).astype(int)\n",
    "    print(n)\n",
    "    for i in range(0,n):\n",
    "        print(str(i+1)+'th slice')\n",
    "        img_block[i*2000:(i+1)*2000,:,:,:]=sess.run(model_dict['outputs'], \n",
    "                                    feed_dict={model_dict['inputs']:img_32[i*2000:(i+1)*2000,:,:,:]})\n",
    "    img_block[n*2000:,:,:,:]=sess.run(model_dict['outputs'], \n",
    "                                    feed_dict={model_dict['inputs']:img_32[n*2000:,:,:,:]})\n",
    "        \n",
    "    img_recon=block2img(img_block,(w,l))\n",
    "    img_recon = convert2uint8(img_recon*255.)\n",
    "    skimage.io.imsave(outpath,img_recon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
