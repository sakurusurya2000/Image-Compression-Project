{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read CIFAR images\n",
    "\n",
    "import read_cifar10 as cf10\n",
    "\n",
    "#@read_data.restartable\n",
    "def cifar10_dataset_generator(dataset_name, batch_size, restrict_size=1000):\n",
    "    assert dataset_name in ['train', 'test']\n",
    "    assert batch_size > 0 or batch_size == -1  # -1 for entire dataset\n",
    "    \n",
    "    X_all_unrestricted, y_all = (cf10.load_training_data() if dataset_name == 'train'\n",
    "                                 else cf10.load_test_data())\n",
    "    \n",
    "    actual_restrict_size = restrict_size if dataset_name == 'train' else int(1e10)\n",
    "    X_all = X_all_unrestricted[:actual_restrict_size]\n",
    "    data_len = X_all.shape[0]\n",
    "    batch_size = batch_size if batch_size > 0 else data_len\n",
    "    \n",
    "    X_all_padded = np.concatenate([X_all, X_all[:batch_size]], axis=0)\n",
    "    y_all_padded = np.concatenate([y_all, y_all[:batch_size]], axis=0)\n",
    "    \n",
    "    for slice_i in range(math.ceil(data_len / batch_size)):\n",
    "        idx = slice_i * batch_size\n",
    "        #X_batch = X_all_padded[idx:idx + batch_size]\n",
    "        X_batch = X_all_padded[idx:idx + batch_size]*255  # bugfix: thanks Zezhou Sun!\n",
    "        y_batch = np.ravel(y_all_padded[idx:idx + batch_size])\n",
    "        yield X_batch.astype(np.uint8), y_batch.astype(np.uint8)\n",
    "\n",
    "cifar10_dataset_generators = {\n",
    "    'train': cifar10_dataset_generator('train', 1000),\n",
    "    'test': cifar10_dataset_generator('test', -1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load cifar-10 data\n",
    "cf10_tr=cf10.load_training_data()\n",
    "cf10_tr_img=cf10_tr[0]\n",
    "cf10_tr_label = cf10_tr[1]\n",
    "\n",
    "cf10_test=cf10.load_test_data()\n",
    "cf10_test_img=cf10_test[0]\n",
    "cf10_test_label = cf10_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import skimage.io\n",
    "def img2block(im):\n",
    "    '''\n",
    "    Image patching code. It patches a given RGB image into 32x32 blocks and returns a 4D array with size \n",
    "    [number_of_patches,32,32,3]\n",
    "    '''\n",
    "    im = im.astype(np.float32)\n",
    "    row,col,color = im.shape\n",
    "    im_bl=np.zeros((int(row*col/1024),32,32,3)).astype(np.float32)\n",
    "    count=0\n",
    "    for i in range(0,row-row%32,32):\n",
    "        for j in range(0,col-col%32,32):\n",
    "            im_bl[count,:,:,:]=im[i:i+32,j:j+32,:]\n",
    "            count = count +1\n",
    "    im_bl=im_bl/255.\n",
    "    return im_bl\n",
    "\n",
    "def block2img(img_blocks,img_size):\n",
    "    '''\n",
    "    Function for reconstructing the image back from patches\n",
    "    '''\n",
    "    row,col = img_size\n",
    "    img=np.zeros((row,col,3)).astype(np.float32)\n",
    "    n,k,l,c=img_blocks.shape\n",
    "                 \n",
    "    for i in range(0,int(row/k)):\n",
    "        for j in range(0,int(col/k)):\n",
    "            img[i*k:(i+1)*k,j*l:(j+1)*l,:]=img_blocks[int(i*col/k+j),:,:,:]\n",
    "    return img\n",
    "\n",
    "#Get the patches of lena image\n",
    "lena_img = skimage.io.imread('../test_img/lena512color.tiff')\n",
    "lena_32=img2block(lena_img)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for converting a double to uint8\n",
    "def convert2uint8(img):\n",
    "    img[img>255]=255\n",
    "    img[img<0]=0\n",
    "    return img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/cnn_autoencoder\n",
      "/tmp/cnn_autoencoderFT\n"
     ]
    }
   ],
   "source": [
    "#Create the inputs in the desired format\n",
    "x_tr = cf10_tr_img.astype(np.float32)#*255.\n",
    "x_test = cf10_test_img.astype(np.float32)#*255.\n",
    "x_test=x_test[:200,:,:,:]\n",
    "img = skimage.io.imread('../test_img_old/lena512color.tiff')\n",
    "img_32=img2block(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_autoencoder(x_,kernels1=[5,7],kernels2=[7,5],filters1=[16,128],filters2=[128,3],pool_size=[1,2,2,1]):\n",
    "    '''\n",
    "    Autoencoder network\n",
    "    \n",
    "    Inputs:\n",
    "    x_ (tf.placeholder) : Input tensor\n",
    "    kernels1 (1D array) : Size of the encoder kernels (assumed square kernels)\n",
    "    kernels2 (1D array) : Size of the decoder kernels (assumed square kernels)\n",
    "    filters1 (1D array) : Number of filters in encoder layers\n",
    "    filters2 (1D array) : Number of filters in decoder layers\n",
    "    pool_size (1D array): Pooling size in each layer. Its length must be equal to len(kernels1)+len(kernels2)\n",
    "                          First len(kernels1) terms will be used as pooling layers of encoder/\n",
    "                          Remainin terms will be used as unpooling layers of decoder\n",
    "                          \n",
    "    Returns:\n",
    "    out_ (tf.placeholder)     : Output of the autoencoder without quantization in the middle\n",
    "    out_quant (tf.placeholder): Output of the autoencoder with quantization in the middle\n",
    "    '''\n",
    "    out_=x_\n",
    "    \n",
    "    #Encoder\n",
    "    for k in range(len(kernels1)):\n",
    "        conv = tf.layers.conv2d(inputs=out_,\n",
    "                                filters=filters1[k],\n",
    "                                kernel_size=[kernels1[k],kernels1[k]],\n",
    "                                padding=\"same\",\n",
    "                                activation=tf.nn.relu,\n",
    "                                name='conv'+str(k))\n",
    "        pool_now=pool_size[k]\n",
    "        if(pool_now==1):\n",
    "            out_=conv\n",
    "        else:\n",
    "            out_ = tf.layers.max_pooling2d(inputs=conv, \n",
    "                                           pool_size=[pool_now,pool_now], \n",
    "                                           strides=pool_now,\n",
    "                                           name = 'pool'+str(k))\n",
    "        \n",
    "        \n",
    "    #Quantization of output\n",
    "    out_quant=tf.round(out_*256.)/256.\n",
    "\n",
    "    #Decoder\n",
    "    for k in range(len(kernels2)):\n",
    "        with tf.variable_scope(\"deconv\") as var_scope:\n",
    "            pool_now=pool_size[k+len(kernels1)]\n",
    "            if(pool_now==1):\n",
    "                x_up=out_\n",
    "                out_ = tf.layers.conv2d(inputs=x_up,\n",
    "                                        filters=filters2[k],\n",
    "                                        kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                        padding=\"same\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        name='deconv'+str(k))\n",
    "                var_scope.reuse_variables() \n",
    "                x_quant_up=out_quant\n",
    "                out_quant = tf.layers.conv2d(inputs=x_quant_up,\n",
    "                                            filters=filters2[k],\n",
    "                                            kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                            padding=\"same\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            name='deconv'+str(k))\n",
    "            else:\n",
    "                #Bilinear interpolation of images\n",
    "                sh = out_.get_shape().as_list()\n",
    "                x_up=tf.image.resize_images(out_,[sh[1]*pool_now,sh[2]*pool_now])\n",
    "                #Convolution\n",
    "                out_ = tf.layers.conv2d(inputs=x_up,\n",
    "                                        filters=filters2[k],\n",
    "                                        kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                        padding=\"same\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        name='deconv'+str(k))\n",
    "                var_scope.reuse_variables() \n",
    "                x_quant_up=tf.image.resize_images(out_quant,[sh[1]*pool_now,sh[2]*pool_now])\n",
    "                out_quant = tf.layers.conv2d(inputs=x_quant_up,\n",
    "                                            filters=filters2[k],\n",
    "                                            kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                            padding=\"same\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            name='deconv'+str(k))\n",
    "\n",
    "\n",
    "    return out_,out_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_classification_loss_mse(kernels1=[5,7],kernels2=[7,5],\n",
    "                                 filters1=[16,128],filters2=[128,3],\n",
    "                                pool_size=[1,2,2,1],learning_rate=1.,FT=False):\n",
    "    '''\n",
    "    MSE based autoencoder optimizer.\n",
    "    \n",
    "    Inputs:\n",
    "    kernels1 (1D array) : Size of the encoder kernels (assumed square kernels)\n",
    "    kernels2 (1D array) : Size of the decoder kernels (assumed square kernels)\n",
    "    filters1 (1D array) : Number of filters in encoder layers\n",
    "    filters2 (1D array) : Number of filters in decoder layers\n",
    "    pool_size (1D array): Pooling size in each layer. Its length must be equal to len(kernels1)+len(kernels2)\n",
    "                          First len(kernels1) terms will be used as pooling layers of encoder/\n",
    "                          Remainin terms will be used as unpooling layers of decoder\n",
    "    learning_rate(float): Learning rate of the optimizer\n",
    "    FT (boolean)        : Boolean value for fine-tuning operation on decoder weights\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    model_dict          : Dictionary of the required output files\n",
    "    '''\n",
    "    \n",
    "    with tf.Graph().as_default() as g:\n",
    "        with tf.device(\"/gpu:0\"):  # use gpu:0 if on GPU\n",
    "            x_ = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "            (x_out,x_out_quant)=cnn_autoencoder(x_,pool_size=pool_size,kernels1=kernels1,filters1=filters1,\n",
    "                                kernels2=kernels2,filters2=filters2)\n",
    "\n",
    "            mse_loss1=tf.reduce_mean(tf.subtract(x_,x_out)**2)\n",
    "            mse_loss2=tf.reduce_mean(tf.subtract(x_,x_out_quant)**2)\n",
    "            \n",
    "            trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            if(FT):\n",
    "                with tf.variable_scope('deconv', reuse=True) as vs:\n",
    "                    var_list=[v for v in tf.global_variables() if v.name.startswith(vs.name)]\n",
    "                train_op = trainer.minimize(mse_loss1,var_list=var_list)\n",
    "            else:\n",
    "                train_op = trainer.minimize(mse_loss1)\n",
    "\n",
    "    model_dict = {'graph': g, 'inputs': x_,'outputs':x_out, 'train_op': train_op, 'loss1': mse_loss1,'loss2': mse_loss2}\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model_dict,x_tr=xt_tr,x_test=x_test,x_32=img_32, train_every=100, test_every=200, load=False,\n",
    "                learning_rate=1.,fname='cifar10_recon',outname='/tmp/cnn_autoencoder',ftname='/tmp/cnn_autoencoder'):\n",
    "    '''\n",
    "    Inputs:\n",
    "    model_dict: Output of apply_classification_loss_mse\n",
    "    x_tr      : Training images\n",
    "    x_test    : Test Images\n",
    "    x_32      : 32x32 patches of a big image\n",
    "    load      : Boolean for loading the weights from pre-trained network\n",
    "    fname     : Directory to save outputs\n",
    "    outname   : Directory to save (load=False) or load (load=True) weights\n",
    "    ftname    : Directory to save new weights when load+True\n",
    "    '''\n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver=tf.train.Saver()\n",
    "        if(load):\n",
    "            saver.restore(sess, outname)\n",
    "            print(\"Model loaded\")\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        ids=[i for i in range(100)]\n",
    "        for iter_i in range(20001):\n",
    "            batch_xs = x_tr[ids,:,:,:] \n",
    "            ids=[(ids[0]+100+i)%x_tr.shape[0] for i in range(100)]\n",
    "            sess.run(model_dict['train_op'], feed_dict={model_dict['inputs']: batch_xs})\n",
    "            \n",
    "            # test trained model\n",
    "            if iter_i % train_every == 0:\n",
    "                tf_feed_dict = {model_dict['inputs']: batch_xs}\n",
    "                loss_val = sess.run(model_dict['loss1'], feed_dict={model_dict['inputs']: batch_xs})\n",
    "                print('iteration %d\\t train mse: %.3E\\t'%(iter_i,loss_val))\n",
    "                if iter_i % test_every == 0:\n",
    "                    #tf_feed_dict = {x_: x_test}\n",
    "                    loss_val1 = sess.run(model_dict['loss1'], feed_dict={model_dict['inputs']: x_test})\n",
    "                    loss_val2 = sess.run(model_dict['loss2'], feed_dict={model_dict['inputs']: x_test})\n",
    "                    print('iteration %d\\t TEST MSE: %.3E\\t TEST MSE(Quantized): %.3E\\t'%(iter_i,loss_val1,loss_val2))\n",
    "                    \n",
    "                    img_block=sess.run(model_dict['outputs'], \n",
    "                                       feed_dict={model_dict['inputs']:img_32})\n",
    "                    x_from_test=sess.run(model_dict['outputs'], \n",
    "                                         feed_dict={model_dict['inputs']:x_test[:5,:,:,:].reshape([-1,32,32,3])})\n",
    "                    \n",
    "                    img_recon=block2img(img_block,(512,512))\n",
    "                    img_recon = convert2uint8(img_recon*255.)\n",
    "                    skimage.io.imsave('../'+fname+'/img32_recon_'+str(int(iter_i/test_every))+'.tiff',img_recon)\n",
    "\n",
    "                    for i in range(5):\n",
    "                        img_recon=convert2uint8((255*x_from_test[i,:,:,:]).reshape([32,32,3])).astype(np.uint8)\n",
    "                        skimage.io.imsave('../'+fname+'/test'+str(i)+'_'+str(int(iter_i/test_every))+'.tiff',img_recon)\n",
    "                        \n",
    "        saver = tf.train.Saver()\n",
    "        if(load):\n",
    "            outname=ftname\n",
    "        save_path = saver.save(sess, outname)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\t train mse: 9.568E-02\t\n",
      "iteration 0\t TEST MSE: 2.946E-01\t TEST MSE(Quantized): 2.946E-01\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/lena4_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/test0_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: ../cifar10_recon0/test1_0.tiff is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100\t train mse: 7.535E-02\t\n",
      "iteration 200\t train mse: 1.790E-02\t\n",
      "iteration 300\t train mse: 9.950E-03\t\n",
      "iteration 400\t train mse: 1.225E-02\t\n",
      "iteration 500\t train mse: 7.430E-03\t\n",
      "iteration 600\t train mse: 1.040E-02\t\n",
      "iteration 700\t train mse: 7.658E-03\t\n",
      "iteration 800\t train mse: 7.549E-03\t\n",
      "iteration 900\t train mse: 7.063E-03\t\n",
      "iteration 1000\t train mse: 6.948E-03\t\n",
      "iteration 1100\t train mse: 5.530E-03\t\n",
      "iteration 1200\t train mse: 5.094E-03\t\n",
      "iteration 1300\t train mse: 4.819E-03\t\n",
      "iteration 1400\t train mse: 4.230E-03\t\n",
      "iteration 1500\t train mse: 4.170E-03\t\n",
      "iteration 1600\t train mse: 4.208E-03\t\n",
      "iteration 1700\t train mse: 4.228E-03\t\n",
      "iteration 1800\t train mse: 3.637E-03\t\n",
      "iteration 1900\t train mse: 4.001E-03\t\n",
      "iteration 2000\t train mse: 3.797E-03\t\n",
      "iteration 2000\t TEST MSE: 2.724E-02\t TEST MSE(Quantized): 2.725E-02\t\n",
      "iteration 2100\t train mse: 3.080E-03\t\n",
      "iteration 2200\t train mse: 3.372E-03\t\n",
      "iteration 2300\t train mse: 3.226E-03\t\n",
      "iteration 2400\t train mse: 4.175E-03\t\n",
      "iteration 2500\t train mse: 2.448E-03\t\n",
      "iteration 2600\t train mse: 3.145E-03\t\n",
      "iteration 2700\t train mse: 4.213E-03\t\n",
      "iteration 2800\t train mse: 3.234E-03\t\n",
      "iteration 2900\t train mse: 2.676E-03\t\n",
      "iteration 3000\t train mse: 2.833E-03\t\n",
      "iteration 3100\t train mse: 2.526E-03\t\n",
      "iteration 3200\t train mse: 2.834E-03\t\n",
      "iteration 3300\t train mse: 2.660E-03\t\n",
      "iteration 3400\t train mse: 1.917E-03\t\n",
      "iteration 3500\t train mse: 3.510E-03\t\n",
      "iteration 3600\t train mse: 2.578E-03\t\n",
      "iteration 3700\t train mse: 2.306E-03\t\n",
      "iteration 3800\t train mse: 2.592E-03\t\n",
      "iteration 3900\t train mse: 2.427E-03\t\n",
      "iteration 4000\t train mse: 2.385E-03\t\n",
      "iteration 4000\t TEST MSE: 1.708E-02\t TEST MSE(Quantized): 1.708E-02\t\n",
      "iteration 4100\t train mse: 1.929E-03\t\n",
      "iteration 4200\t train mse: 2.098E-03\t\n",
      "iteration 4300\t train mse: 1.910E-03\t\n",
      "iteration 4400\t train mse: 1.860E-03\t\n",
      "iteration 4500\t train mse: 2.520E-03\t\n",
      "iteration 4600\t train mse: 2.063E-03\t\n",
      "iteration 4700\t train mse: 2.307E-03\t\n",
      "iteration 4800\t train mse: 2.316E-03\t\n",
      "iteration 4900\t train mse: 1.755E-03\t\n",
      "iteration 5000\t train mse: 1.815E-03\t\n",
      "iteration 5100\t train mse: 2.022E-03\t\n",
      "iteration 5200\t train mse: 1.943E-03\t\n",
      "iteration 5300\t train mse: 2.124E-03\t\n",
      "iteration 5400\t train mse: 2.075E-03\t\n",
      "iteration 5500\t train mse: 1.972E-03\t\n",
      "iteration 5600\t train mse: 1.871E-03\t\n",
      "iteration 5700\t train mse: 2.174E-03\t\n",
      "iteration 5800\t train mse: 2.290E-03\t\n",
      "iteration 5900\t train mse: 1.889E-03\t\n",
      "iteration 6000\t train mse: 1.461E-03\t\n",
      "iteration 6000\t TEST MSE: 1.414E-02\t TEST MSE(Quantized): 1.415E-02\t\n",
      "iteration 6100\t train mse: 1.731E-03\t\n",
      "iteration 6200\t train mse: 2.106E-03\t\n",
      "iteration 6300\t train mse: 2.222E-03\t\n",
      "iteration 6400\t train mse: 1.817E-03\t\n",
      "iteration 6500\t train mse: 1.710E-03\t\n",
      "iteration 6600\t train mse: 1.840E-03\t\n",
      "iteration 6700\t train mse: 2.190E-03\t\n",
      "iteration 6800\t train mse: 1.936E-03\t\n",
      "iteration 6900\t train mse: 2.138E-03\t\n",
      "iteration 7000\t train mse: 1.363E-03\t\n",
      "iteration 7100\t train mse: 2.118E-03\t\n",
      "iteration 7200\t train mse: 2.042E-03\t\n",
      "iteration 7300\t train mse: 1.997E-03\t\n",
      "iteration 7400\t train mse: 1.627E-03\t\n",
      "iteration 7500\t train mse: 1.273E-03\t\n",
      "iteration 7600\t train mse: 1.884E-03\t\n",
      "iteration 7700\t train mse: 1.681E-03\t\n",
      "iteration 7800\t train mse: 1.594E-03\t\n",
      "iteration 7900\t train mse: 1.750E-03\t\n",
      "iteration 8000\t train mse: 1.442E-03\t\n",
      "iteration 8000\t TEST MSE: 1.291E-02\t TEST MSE(Quantized): 1.291E-02\t\n",
      "iteration 8100\t train mse: 1.863E-03\t\n",
      "iteration 8200\t train mse: 1.670E-03\t\n",
      "iteration 8300\t train mse: 1.455E-03\t\n",
      "iteration 8400\t train mse: 2.067E-03\t\n",
      "iteration 8500\t train mse: 1.859E-03\t\n",
      "iteration 8600\t train mse: 1.868E-03\t\n",
      "iteration 8700\t train mse: 1.424E-03\t\n",
      "iteration 8800\t train mse: 1.368E-03\t\n",
      "iteration 8900\t train mse: 1.643E-03\t\n",
      "iteration 9000\t train mse: 1.624E-03\t\n",
      "iteration 9100\t train mse: 1.632E-03\t\n",
      "iteration 9200\t train mse: 1.479E-03\t\n",
      "iteration 9300\t train mse: 1.641E-03\t\n",
      "iteration 9400\t train mse: 1.549E-03\t\n",
      "iteration 9500\t train mse: 1.908E-03\t\n",
      "iteration 9600\t train mse: 1.610E-03\t\n",
      "iteration 9700\t train mse: 1.544E-03\t\n",
      "iteration 9800\t train mse: 1.643E-03\t\n",
      "iteration 9900\t train mse: 1.288E-03\t\n",
      "iteration 10000\t train mse: 1.731E-03\t\n",
      "iteration 10000\t TEST MSE: 1.213E-02\t TEST MSE(Quantized): 1.214E-02\t\n",
      "iteration 10100\t train mse: 1.515E-03\t\n",
      "iteration 10200\t train mse: 1.682E-03\t\n",
      "iteration 10300\t train mse: 1.880E-03\t\n",
      "iteration 10400\t train mse: 1.393E-03\t\n",
      "iteration 10500\t train mse: 1.911E-03\t\n",
      "iteration 10600\t train mse: 1.629E-03\t\n",
      "iteration 10700\t train mse: 2.102E-03\t\n",
      "iteration 10800\t train mse: 2.062E-03\t\n",
      "iteration 10900\t train mse: 1.325E-03\t\n",
      "iteration 11000\t train mse: 1.361E-03\t\n",
      "iteration 11100\t train mse: 1.572E-03\t\n",
      "iteration 11200\t train mse: 1.530E-03\t\n",
      "iteration 11300\t train mse: 1.684E-03\t\n",
      "iteration 11400\t train mse: 1.574E-03\t\n",
      "iteration 11500\t train mse: 1.398E-03\t\n",
      "iteration 11600\t train mse: 1.574E-03\t\n",
      "iteration 11700\t train mse: 1.692E-03\t\n",
      "iteration 11800\t train mse: 1.304E-03\t\n",
      "iteration 11900\t train mse: 1.521E-03\t\n",
      "iteration 12000\t train mse: 1.122E-03\t\n",
      "iteration 12000\t TEST MSE: 1.149E-02\t TEST MSE(Quantized): 1.149E-02\t\n",
      "iteration 12100\t train mse: 1.615E-03\t\n",
      "iteration 12200\t train mse: 1.408E-03\t\n",
      "iteration 12300\t train mse: 1.691E-03\t\n",
      "iteration 12400\t train mse: 1.497E-03\t\n",
      "iteration 12500\t train mse: 1.509E-03\t\n",
      "iteration 12600\t train mse: 1.286E-03\t\n",
      "iteration 12700\t train mse: 1.515E-03\t\n",
      "iteration 12800\t train mse: 1.442E-03\t\n",
      "iteration 12900\t train mse: 1.321E-03\t\n",
      "iteration 13000\t train mse: 1.477E-03\t\n",
      "iteration 13100\t train mse: 1.477E-03\t\n",
      "iteration 13200\t train mse: 1.529E-03\t\n",
      "iteration 13300\t train mse: 1.413E-03\t\n",
      "iteration 13400\t train mse: 1.532E-03\t\n",
      "iteration 13500\t train mse: 1.364E-03\t\n",
      "iteration 13600\t train mse: 1.367E-03\t\n",
      "iteration 13700\t train mse: 1.361E-03\t\n",
      "iteration 13800\t train mse: 1.473E-03\t\n",
      "iteration 13900\t train mse: 1.732E-03\t\n",
      "iteration 14000\t train mse: 1.045E-03\t\n",
      "iteration 14000\t TEST MSE: 1.104E-02\t TEST MSE(Quantized): 1.104E-02\t\n",
      "iteration 14100\t train mse: 1.613E-03\t\n",
      "iteration 14200\t train mse: 1.736E-03\t\n",
      "iteration 14300\t train mse: 1.479E-03\t\n",
      "iteration 14400\t train mse: 1.144E-03\t\n",
      "iteration 14500\t train mse: 1.407E-03\t\n",
      "iteration 14600\t train mse: 1.328E-03\t\n",
      "iteration 14700\t train mse: 1.538E-03\t\n",
      "iteration 14800\t train mse: 1.503E-03\t\n",
      "iteration 14900\t train mse: 1.188E-03\t\n",
      "iteration 15000\t train mse: 1.971E-03\t\n",
      "iteration 15100\t train mse: 1.547E-03\t\n",
      "iteration 15200\t train mse: 1.667E-03\t\n",
      "iteration 15300\t train mse: 1.515E-03\t\n",
      "iteration 15400\t train mse: 1.408E-03\t\n",
      "iteration 15500\t train mse: 1.440E-03\t\n",
      "iteration 15600\t train mse: 1.187E-03\t\n",
      "iteration 15700\t train mse: 1.508E-03\t\n",
      "iteration 15800\t train mse: 1.173E-03\t\n",
      "iteration 15900\t train mse: 1.235E-03\t\n",
      "iteration 16000\t train mse: 1.576E-03\t\n",
      "iteration 16000\t TEST MSE: 1.066E-02\t TEST MSE(Quantized): 1.066E-02\t\n",
      "iteration 16100\t train mse: 1.313E-03\t\n",
      "iteration 16200\t train mse: 1.442E-03\t\n",
      "iteration 16300\t train mse: 1.350E-03\t\n",
      "iteration 16400\t train mse: 1.189E-03\t\n",
      "iteration 16500\t train mse: 1.317E-03\t\n",
      "iteration 16600\t train mse: 1.357E-03\t\n",
      "iteration 16700\t train mse: 1.448E-03\t\n",
      "iteration 16800\t train mse: 1.580E-03\t\n",
      "iteration 16900\t train mse: 1.516E-03\t\n",
      "iteration 17000\t train mse: 1.353E-03\t\n",
      "iteration 17100\t train mse: 1.419E-03\t\n",
      "iteration 17200\t train mse: 1.335E-03\t\n",
      "iteration 17300\t train mse: 1.642E-03\t\n",
      "iteration 17400\t train mse: 1.203E-03\t\n",
      "iteration 17500\t train mse: 1.147E-03\t\n",
      "iteration 17600\t train mse: 1.105E-03\t\n",
      "iteration 17700\t train mse: 1.368E-03\t\n",
      "iteration 17800\t train mse: 1.869E-03\t\n",
      "iteration 17900\t train mse: 1.318E-03\t\n",
      "iteration 18000\t train mse: 1.391E-03\t\n",
      "iteration 18000\t TEST MSE: 1.040E-02\t TEST MSE(Quantized): 1.040E-02\t\n",
      "iteration 18100\t train mse: 1.334E-03\t\n",
      "iteration 18200\t train mse: 1.655E-03\t\n",
      "iteration 18300\t train mse: 1.389E-03\t\n",
      "iteration 18400\t train mse: 1.567E-03\t\n",
      "iteration 18500\t train mse: 8.882E-04\t\n",
      "iteration 18600\t train mse: 1.608E-03\t\n",
      "iteration 18700\t train mse: 1.574E-03\t\n",
      "iteration 18800\t train mse: 1.415E-03\t\n",
      "iteration 18900\t train mse: 1.385E-03\t\n",
      "iteration 19000\t train mse: 1.125E-03\t\n",
      "iteration 19100\t train mse: 1.494E-03\t\n",
      "iteration 19200\t train mse: 1.336E-03\t\n",
      "iteration 19300\t train mse: 1.070E-03\t\n",
      "iteration 19400\t train mse: 1.359E-03\t\n",
      "iteration 19500\t train mse: 1.125E-03\t\n",
      "iteration 19600\t train mse: 1.563E-03\t\n",
      "iteration 19700\t train mse: 1.285E-03\t\n",
      "iteration 19800\t train mse: 1.273E-03\t\n",
      "iteration 19900\t train mse: 1.651E-03\t\n",
      "iteration 20000\t train mse: 1.397E-03\t\n",
      "iteration 20000\t TEST MSE: 1.020E-02\t TEST MSE(Quantized): 1.020E-02\t\n",
      "iteration 20100\t train mse: 1.444E-03\t\n",
      "iteration 20200\t train mse: 1.090E-03\t\n",
      "iteration 20300\t train mse: 1.062E-03\t\n",
      "iteration 20400\t train mse: 1.228E-03\t\n",
      "iteration 20500\t train mse: 1.284E-03\t\n",
      "iteration 20600\t train mse: 1.290E-03\t\n",
      "iteration 20700\t train mse: 1.074E-03\t\n",
      "iteration 20800\t train mse: 1.436E-03\t\n",
      "iteration 20900\t train mse: 1.219E-03\t\n",
      "iteration 21000\t train mse: 1.535E-03\t\n",
      "iteration 21100\t train mse: 1.342E-03\t\n",
      "iteration 21200\t train mse: 1.292E-03\t\n",
      "iteration 21300\t train mse: 1.412E-03\t\n",
      "iteration 21400\t train mse: 1.125E-03\t\n",
      "iteration 21500\t train mse: 1.522E-03\t\n",
      "iteration 21600\t train mse: 1.110E-03\t\n",
      "iteration 21700\t train mse: 1.366E-03\t\n",
      "iteration 21800\t train mse: 1.323E-03\t\n",
      "iteration 21900\t train mse: 1.231E-03\t\n",
      "iteration 22000\t train mse: 1.574E-03\t\n",
      "iteration 22000\t TEST MSE: 1.001E-02\t TEST MSE(Quantized): 1.001E-02\t\n",
      "iteration 22100\t train mse: 1.336E-03\t\n",
      "iteration 22200\t train mse: 1.645E-03\t\n",
      "iteration 22300\t train mse: 1.694E-03\t\n",
      "iteration 22400\t train mse: 1.171E-03\t\n",
      "iteration 22500\t train mse: 1.024E-03\t\n",
      "iteration 22600\t train mse: 1.234E-03\t\n",
      "iteration 22700\t train mse: 1.291E-03\t\n",
      "iteration 22800\t train mse: 1.398E-03\t\n",
      "iteration 22900\t train mse: 1.460E-03\t\n",
      "iteration 23000\t train mse: 1.101E-03\t\n",
      "iteration 23100\t train mse: 1.350E-03\t\n",
      "iteration 23200\t train mse: 1.422E-03\t\n",
      "iteration 23300\t train mse: 1.172E-03\t\n",
      "iteration 23400\t train mse: 1.229E-03\t\n",
      "iteration 23500\t train mse: 1.007E-03\t\n",
      "iteration 23600\t train mse: 1.325E-03\t\n",
      "iteration 23700\t train mse: 1.185E-03\t\n",
      "iteration 23800\t train mse: 1.387E-03\t\n",
      "iteration 23900\t train mse: 1.243E-03\t\n",
      "iteration 24000\t train mse: 1.335E-03\t\n",
      "iteration 24000\t TEST MSE: 9.872E-03\t TEST MSE(Quantized): 9.873E-03\t\n",
      "iteration 24100\t train mse: 1.016E-03\t\n",
      "iteration 24200\t train mse: 1.192E-03\t\n",
      "iteration 24300\t train mse: 1.258E-03\t\n",
      "iteration 24400\t train mse: 1.219E-03\t\n",
      "iteration 24500\t train mse: 1.311E-03\t\n",
      "iteration 24600\t train mse: 1.223E-03\t\n",
      "iteration 24700\t train mse: 1.172E-03\t\n",
      "iteration 24800\t train mse: 1.264E-03\t\n",
      "iteration 24900\t train mse: 1.170E-03\t\n",
      "iteration 25000\t train mse: 1.094E-03\t\n",
      "iteration 25100\t train mse: 1.048E-03\t\n",
      "iteration 25200\t train mse: 1.229E-03\t\n",
      "iteration 25300\t train mse: 1.496E-03\t\n",
      "iteration 25400\t train mse: 1.586E-03\t\n",
      "iteration 25500\t train mse: 8.713E-04\t\n",
      "iteration 25600\t train mse: 1.327E-03\t\n",
      "iteration 25700\t train mse: 1.552E-03\t\n",
      "iteration 25800\t train mse: 1.444E-03\t\n",
      "iteration 25900\t train mse: 1.130E-03\t\n",
      "iteration 26000\t train mse: 1.264E-03\t\n",
      "iteration 26000\t TEST MSE: 9.735E-03\t TEST MSE(Quantized): 9.734E-03\t\n",
      "iteration 26100\t train mse: 1.237E-03\t\n",
      "iteration 26200\t train mse: 1.508E-03\t\n",
      "iteration 26300\t train mse: 1.337E-03\t\n",
      "iteration 26400\t train mse: 1.073E-03\t\n",
      "iteration 26500\t train mse: 1.643E-03\t\n",
      "iteration 26600\t train mse: 1.308E-03\t\n",
      "iteration 26700\t train mse: 1.522E-03\t\n",
      "iteration 26800\t train mse: 1.302E-03\t\n",
      "iteration 26900\t train mse: 1.133E-03\t\n",
      "iteration 27000\t train mse: 1.289E-03\t\n",
      "iteration 27100\t train mse: 9.998E-04\t\n",
      "iteration 27200\t train mse: 1.312E-03\t\n",
      "iteration 27300\t train mse: 1.162E-03\t\n",
      "iteration 27400\t train mse: 1.041E-03\t\n",
      "iteration 27500\t train mse: 1.293E-03\t\n",
      "iteration 27600\t train mse: 1.080E-03\t\n",
      "iteration 27700\t train mse: 1.154E-03\t\n",
      "iteration 27800\t train mse: 1.358E-03\t\n",
      "iteration 27900\t train mse: 1.190E-03\t\n",
      "iteration 28000\t train mse: 1.162E-03\t\n",
      "iteration 28000\t TEST MSE: 9.644E-03\t TEST MSE(Quantized): 9.645E-03\t\n",
      "iteration 28100\t train mse: 1.079E-03\t\n",
      "iteration 28200\t train mse: 1.151E-03\t\n",
      "iteration 28300\t train mse: 1.456E-03\t\n",
      "iteration 28400\t train mse: 1.201E-03\t\n",
      "iteration 28500\t train mse: 1.366E-03\t\n",
      "iteration 28600\t train mse: 1.397E-03\t\n",
      "iteration 28700\t train mse: 1.362E-03\t\n",
      "iteration 28800\t train mse: 1.281E-03\t\n",
      "iteration 28900\t train mse: 1.071E-03\t\n",
      "iteration 29000\t train mse: 1.183E-03\t\n",
      "iteration 29100\t train mse: 1.016E-03\t\n",
      "iteration 29200\t train mse: 1.207E-03\t\n",
      "iteration 29300\t train mse: 1.630E-03\t\n",
      "iteration 29400\t train mse: 1.114E-03\t\n",
      "iteration 29500\t train mse: 1.313E-03\t\n",
      "iteration 29600\t train mse: 1.183E-03\t\n",
      "iteration 29700\t train mse: 1.318E-03\t\n",
      "iteration 29800\t train mse: 1.232E-03\t\n",
      "iteration 29900\t train mse: 1.488E-03\t\n",
      "iteration 30000\t train mse: 7.599E-04\t\n",
      "iteration 30000\t TEST MSE: 9.556E-03\t TEST MSE(Quantized): 9.556E-03\t\n",
      "iteration 30100\t train mse: 1.318E-03\t\n",
      "iteration 30200\t train mse: 1.388E-03\t\n",
      "iteration 30300\t train mse: 1.161E-03\t\n",
      "iteration 30400\t train mse: 1.236E-03\t\n",
      "iteration 30500\t train mse: 1.076E-03\t\n",
      "iteration 30600\t train mse: 1.369E-03\t\n",
      "iteration 30700\t train mse: 1.088E-03\t\n",
      "iteration 30800\t train mse: 9.925E-04\t\n",
      "iteration 30900\t train mse: 1.172E-03\t\n",
      "iteration 31000\t train mse: 9.217E-04\t\n",
      "iteration 31100\t train mse: 1.414E-03\t\n",
      "iteration 31200\t train mse: 1.124E-03\t\n",
      "iteration 31300\t train mse: 1.332E-03\t\n",
      "iteration 31400\t train mse: 1.344E-03\t\n",
      "iteration 31500\t train mse: 1.360E-03\t\n",
      "iteration 31600\t train mse: 1.157E-03\t\n",
      "iteration 31700\t train mse: 1.085E-03\t\n",
      "iteration 31800\t train mse: 9.901E-04\t\n",
      "iteration 31900\t train mse: 1.127E-03\t\n",
      "iteration 32000\t train mse: 1.298E-03\t\n",
      "iteration 32000\t TEST MSE: 9.507E-03\t TEST MSE(Quantized): 9.509E-03\t\n",
      "iteration 32100\t train mse: 1.206E-03\t\n",
      "iteration 32200\t train mse: 9.801E-04\t\n",
      "iteration 32300\t train mse: 1.411E-03\t\n",
      "iteration 32400\t train mse: 1.142E-03\t\n",
      "iteration 32500\t train mse: 1.281E-03\t\n",
      "iteration 32600\t train mse: 1.206E-03\t\n",
      "iteration 32700\t train mse: 1.189E-03\t\n",
      "iteration 32800\t train mse: 1.331E-03\t\n",
      "iteration 32900\t train mse: 1.111E-03\t\n",
      "iteration 33000\t train mse: 1.458E-03\t\n",
      "iteration 33100\t train mse: 8.794E-04\t\n",
      "iteration 33200\t train mse: 1.237E-03\t\n",
      "iteration 33300\t train mse: 1.510E-03\t\n",
      "iteration 33400\t train mse: 1.092E-03\t\n",
      "iteration 33500\t train mse: 1.501E-03\t\n",
      "iteration 33600\t train mse: 1.258E-03\t\n",
      "iteration 33700\t train mse: 1.571E-03\t\n",
      "iteration 33800\t train mse: 1.490E-03\t\n",
      "iteration 33900\t train mse: 1.136E-03\t\n",
      "iteration 34000\t train mse: 9.381E-04\t\n",
      "iteration 34000\t TEST MSE: 9.420E-03\t TEST MSE(Quantized): 9.421E-03\t\n",
      "iteration 34100\t train mse: 9.173E-04\t\n",
      "iteration 34200\t train mse: 1.206E-03\t\n",
      "iteration 34300\t train mse: 1.278E-03\t\n",
      "iteration 34400\t train mse: 1.365E-03\t\n",
      "iteration 34500\t train mse: 9.620E-04\t\n",
      "iteration 34600\t train mse: 1.186E-03\t\n",
      "iteration 34700\t train mse: 1.287E-03\t\n",
      "iteration 34800\t train mse: 1.164E-03\t\n",
      "iteration 34900\t train mse: 1.014E-03\t\n",
      "iteration 35000\t train mse: 1.116E-03\t\n",
      "iteration 35100\t train mse: 1.060E-03\t\n",
      "iteration 35200\t train mse: 1.092E-03\t\n",
      "iteration 35300\t train mse: 1.292E-03\t\n",
      "iteration 35400\t train mse: 1.132E-03\t\n",
      "iteration 35500\t train mse: 1.236E-03\t\n",
      "iteration 35600\t train mse: 8.693E-04\t\n",
      "iteration 35700\t train mse: 1.148E-03\t\n",
      "iteration 35800\t train mse: 1.065E-03\t\n",
      "iteration 35900\t train mse: 1.092E-03\t\n",
      "iteration 36000\t train mse: 1.271E-03\t\n",
      "iteration 36000\t TEST MSE: 9.346E-03\t TEST MSE(Quantized): 9.348E-03\t\n",
      "iteration 36100\t train mse: 1.202E-03\t\n",
      "iteration 36200\t train mse: 1.164E-03\t\n",
      "iteration 36300\t train mse: 1.207E-03\t\n",
      "iteration 36400\t train mse: 1.106E-03\t\n",
      "iteration 36500\t train mse: 9.217E-04\t\n",
      "iteration 36600\t train mse: 1.189E-03\t\n",
      "iteration 36700\t train mse: 1.220E-03\t\n",
      "iteration 36800\t train mse: 1.397E-03\t\n",
      "iteration 36900\t train mse: 1.334E-03\t\n",
      "iteration 37000\t train mse: 9.218E-04\t\n",
      "iteration 37100\t train mse: 1.296E-03\t\n",
      "iteration 37200\t train mse: 1.251E-03\t\n",
      "iteration 37300\t train mse: 1.453E-03\t\n",
      "iteration 37400\t train mse: 1.090E-03\t\n",
      "iteration 37500\t train mse: 1.168E-03\t\n",
      "iteration 37600\t train mse: 1.116E-03\t\n",
      "iteration 37700\t train mse: 1.290E-03\t\n",
      "iteration 37800\t train mse: 1.275E-03\t\n",
      "iteration 37900\t train mse: 1.076E-03\t\n",
      "iteration 38000\t train mse: 1.405E-03\t\n",
      "iteration 38000\t TEST MSE: 9.315E-03\t TEST MSE(Quantized): 9.316E-03\t\n",
      "iteration 38100\t train mse: 1.233E-03\t\n",
      "iteration 38200\t train mse: 1.457E-03\t\n",
      "iteration 38300\t train mse: 1.301E-03\t\n",
      "iteration 38400\t train mse: 1.061E-03\t\n",
      "iteration 38500\t train mse: 1.178E-03\t\n",
      "iteration 38600\t train mse: 1.020E-03\t\n",
      "iteration 38700\t train mse: 1.284E-03\t\n",
      "iteration 38800\t train mse: 1.102E-03\t\n",
      "iteration 38900\t train mse: 1.025E-03\t\n",
      "iteration 39000\t train mse: 1.291E-03\t\n",
      "iteration 39100\t train mse: 1.037E-03\t\n",
      "iteration 39200\t train mse: 1.149E-03\t\n",
      "iteration 39300\t train mse: 1.174E-03\t\n",
      "iteration 39400\t train mse: 1.158E-03\t\n",
      "iteration 39500\t train mse: 1.003E-03\t\n",
      "iteration 39600\t train mse: 1.044E-03\t\n",
      "iteration 39700\t train mse: 1.169E-03\t\n",
      "iteration 39800\t train mse: 1.374E-03\t\n",
      "iteration 39900\t train mse: 1.070E-03\t\n",
      "iteration 40000\t train mse: 1.348E-03\t\n",
      "iteration 40000\t TEST MSE: 9.293E-03\t TEST MSE(Quantized): 9.294E-03\t\n",
      "iteration 40100\t train mse: 1.340E-03\t\n",
      "iteration 40200\t train mse: 1.017E-03\t\n",
      "iteration 40300\t train mse: 1.177E-03\t\n",
      "iteration 40400\t train mse: 1.018E-03\t\n",
      "iteration 40500\t train mse: 1.192E-03\t\n",
      "iteration 40600\t train mse: 8.518E-04\t\n",
      "iteration 40700\t train mse: 1.149E-03\t\n",
      "iteration 40800\t train mse: 1.635E-03\t\n",
      "iteration 40900\t train mse: 1.061E-03\t\n",
      "iteration 41000\t train mse: 1.105E-03\t\n",
      "iteration 41100\t train mse: 1.149E-03\t\n",
      "iteration 41200\t train mse: 1.033E-03\t\n",
      "iteration 41300\t train mse: 1.210E-03\t\n",
      "iteration 41400\t train mse: 1.396E-03\t\n",
      "iteration 41500\t train mse: 6.742E-04\t\n",
      "iteration 41600\t train mse: 1.334E-03\t\n",
      "iteration 41700\t train mse: 1.345E-03\t\n",
      "iteration 41800\t train mse: 1.284E-03\t\n",
      "iteration 41900\t train mse: 1.191E-03\t\n",
      "iteration 42000\t train mse: 9.866E-04\t\n",
      "iteration 42000\t TEST MSE: 9.220E-03\t TEST MSE(Quantized): 9.222E-03\t\n",
      "iteration 42100\t train mse: 1.344E-03\t\n",
      "iteration 42200\t train mse: 9.785E-04\t\n",
      "iteration 42300\t train mse: 9.488E-04\t\n",
      "iteration 42400\t train mse: 1.140E-03\t\n",
      "iteration 42500\t train mse: 8.999E-04\t\n",
      "iteration 42600\t train mse: 1.372E-03\t\n",
      "iteration 42700\t train mse: 1.085E-03\t\n",
      "iteration 42800\t train mse: 1.341E-03\t\n",
      "iteration 42900\t train mse: 1.244E-03\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-65945b049950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                      pool_size=[1,2,2,2,2,1],learning_rate=7e-5)\n\u001b[1;32m      5\u001b[0m saver = train_model(model_dict, [], train_every=100, test_every=2000,load=False,\n\u001b[0;32m----> 6\u001b[0;31m                     fname='cifar10_recon0',outname='/tmp/cnnx4_test0')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-f8ab3a07436c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_dict, dataset_generators, train_every, test_every, load, learning_rate, fname, outname, ftname)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_op'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# test trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse(kernels1=[5,7,9],kernels2=[9,7,5],\n",
    "                                     filters1=[64,16,3],filters2=[3,3,3],\n",
    "                                     pool_size=[1,2,2,2,2,1],learning_rate=7e-5)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=2000,load=False,\n",
    "                    fname='cifar10_recon0',outname='/tmp/cnnx4_test0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/cnnx4_test7\n",
      "Model loaded\n",
      "iteration 0\t train mse: 9.120E-04\t\n",
      "iteration 0\t TEST MSE: 4.321E-03\t TEST MSE(Quantized): 4.717E-03\t\n",
      "iteration 100\t train mse: 7.661E-04\t\n",
      "iteration 200\t train mse: 9.206E-04\t\n",
      "iteration 300\t train mse: 1.032E-03\t\n",
      "iteration 400\t train mse: 9.364E-04\t\n",
      "iteration 500\t train mse: 1.115E-03\t\n",
      "iteration 600\t train mse: 8.462E-04\t\n",
      "iteration 700\t train mse: 1.093E-03\t\n",
      "iteration 800\t train mse: 9.638E-04\t\n",
      "iteration 900\t train mse: 1.157E-03\t\n",
      "iteration 1000\t train mse: 1.015E-03\t\n",
      "iteration 1000\t TEST MSE: 4.331E-03\t TEST MSE(Quantized): 4.727E-03\t\n",
      "iteration 1100\t train mse: 8.914E-04\t\n",
      "iteration 1200\t train mse: 9.490E-04\t\n",
      "iteration 1300\t train mse: 9.140E-04\t\n",
      "iteration 1400\t train mse: 8.425E-04\t\n",
      "iteration 1500\t train mse: 8.868E-04\t\n",
      "iteration 1600\t train mse: 8.510E-04\t\n",
      "iteration 1700\t train mse: 8.503E-04\t\n",
      "iteration 1800\t train mse: 1.040E-03\t\n",
      "iteration 1900\t train mse: 1.065E-03\t\n",
      "iteration 2000\t train mse: 1.126E-03\t\n",
      "iteration 2000\t TEST MSE: 4.341E-03\t TEST MSE(Quantized): 4.737E-03\t\n",
      "iteration 2100\t train mse: 1.143E-03\t\n",
      "iteration 2200\t train mse: 1.167E-03\t\n",
      "iteration 2300\t train mse: 1.088E-03\t\n",
      "iteration 2400\t train mse: 1.034E-03\t\n",
      "iteration 2500\t train mse: 8.402E-04\t\n",
      "iteration 2600\t train mse: 7.963E-04\t\n",
      "iteration 2700\t train mse: 9.542E-04\t\n",
      "iteration 2800\t train mse: 9.438E-04\t\n",
      "iteration 2900\t train mse: 8.478E-04\t\n",
      "iteration 3000\t train mse: 9.114E-04\t\n",
      "iteration 3000\t TEST MSE: 4.347E-03\t TEST MSE(Quantized): 4.744E-03\t\n",
      "iteration 3100\t train mse: 1.026E-03\t\n",
      "iteration 3200\t train mse: 9.188E-04\t\n",
      "iteration 3300\t train mse: 1.038E-03\t\n",
      "iteration 3400\t train mse: 7.922E-04\t\n",
      "iteration 3500\t train mse: 1.022E-03\t\n",
      "iteration 3600\t train mse: 9.371E-04\t\n",
      "iteration 3700\t train mse: 9.759E-04\t\n",
      "iteration 3800\t train mse: 9.527E-04\t\n",
      "iteration 3900\t train mse: 9.782E-04\t\n",
      "iteration 4000\t train mse: 7.795E-04\t\n",
      "iteration 4000\t TEST MSE: 4.360E-03\t TEST MSE(Quantized): 4.756E-03\t\n",
      "iteration 4100\t train mse: 6.546E-04\t\n",
      "iteration 4200\t train mse: 1.093E-03\t\n",
      "iteration 4300\t train mse: 1.051E-03\t\n",
      "iteration 4400\t train mse: 9.084E-04\t\n",
      "iteration 4500\t train mse: 9.404E-04\t\n",
      "iteration 4600\t train mse: 8.004E-04\t\n",
      "iteration 4700\t train mse: 1.155E-03\t\n",
      "iteration 4800\t train mse: 1.238E-03\t\n",
      "iteration 4900\t train mse: 1.026E-03\t\n",
      "iteration 5000\t train mse: 1.075E-03\t\n",
      "iteration 5000\t TEST MSE: 4.373E-03\t TEST MSE(Quantized): 4.769E-03\t\n",
      "iteration 5100\t train mse: 9.762E-04\t\n",
      "iteration 5200\t train mse: 8.044E-04\t\n",
      "iteration 5300\t train mse: 9.112E-04\t\n",
      "iteration 5400\t train mse: 8.211E-04\t\n",
      "iteration 5500\t train mse: 1.226E-03\t\n",
      "iteration 5600\t train mse: 9.710E-04\t\n",
      "iteration 5700\t train mse: 9.604E-04\t\n",
      "iteration 5800\t train mse: 7.420E-04\t\n",
      "iteration 5900\t train mse: 1.004E-03\t\n",
      "iteration 6000\t train mse: 8.883E-04\t\n",
      "iteration 6000\t TEST MSE: 4.388E-03\t TEST MSE(Quantized): 4.785E-03\t\n",
      "iteration 6100\t train mse: 7.990E-04\t\n",
      "iteration 6200\t train mse: 8.179E-04\t\n",
      "iteration 6300\t train mse: 1.189E-03\t\n",
      "iteration 6400\t train mse: 8.147E-04\t\n",
      "iteration 6500\t train mse: 8.471E-04\t\n",
      "iteration 6600\t train mse: 8.954E-04\t\n",
      "iteration 6700\t train mse: 6.501E-04\t\n",
      "iteration 6800\t train mse: 1.195E-03\t\n",
      "iteration 6900\t train mse: 1.043E-03\t\n",
      "iteration 7000\t train mse: 8.349E-04\t\n",
      "iteration 7000\t TEST MSE: 4.393E-03\t TEST MSE(Quantized): 4.789E-03\t\n",
      "iteration 7100\t train mse: 7.484E-04\t\n",
      "iteration 7200\t train mse: 1.089E-03\t\n",
      "iteration 7300\t train mse: 9.620E-04\t\n",
      "iteration 7400\t train mse: 7.011E-04\t\n",
      "iteration 7500\t train mse: 9.385E-04\t\n",
      "iteration 7600\t train mse: 7.431E-04\t\n",
      "iteration 7700\t train mse: 9.084E-04\t\n",
      "iteration 7800\t train mse: 1.010E-03\t\n",
      "iteration 7900\t train mse: 9.096E-04\t\n",
      "iteration 8000\t train mse: 1.173E-03\t\n",
      "iteration 8000\t TEST MSE: 4.398E-03\t TEST MSE(Quantized): 4.794E-03\t\n",
      "iteration 8100\t train mse: 1.009E-03\t\n",
      "iteration 8200\t train mse: 8.189E-04\t\n",
      "iteration 8300\t train mse: 8.145E-04\t\n",
      "iteration 8400\t train mse: 1.030E-03\t\n",
      "iteration 8500\t train mse: 1.089E-03\t\n",
      "iteration 8600\t train mse: 9.949E-04\t\n",
      "iteration 8700\t train mse: 9.219E-04\t\n",
      "iteration 8800\t train mse: 8.723E-04\t\n",
      "iteration 8900\t train mse: 9.306E-04\t\n",
      "iteration 9000\t train mse: 8.554E-04\t\n",
      "iteration 9000\t TEST MSE: 4.408E-03\t TEST MSE(Quantized): 4.804E-03\t\n",
      "iteration 9100\t train mse: 1.041E-03\t\n",
      "iteration 9200\t train mse: 8.112E-04\t\n",
      "iteration 9300\t train mse: 9.856E-04\t\n",
      "iteration 9400\t train mse: 1.099E-03\t\n",
      "iteration 9500\t train mse: 9.666E-04\t\n",
      "iteration 9600\t train mse: 9.836E-04\t\n",
      "iteration 9700\t train mse: 9.653E-04\t\n",
      "iteration 9800\t train mse: 1.008E-03\t\n",
      "iteration 9900\t train mse: 1.016E-03\t\n",
      "iteration 10000\t train mse: 9.115E-04\t\n",
      "iteration 10000\t TEST MSE: 4.408E-03\t TEST MSE(Quantized): 4.803E-03\t\n",
      "iteration 10100\t train mse: 8.188E-04\t\n",
      "iteration 10200\t train mse: 9.746E-04\t\n",
      "iteration 10300\t train mse: 8.563E-04\t\n",
      "iteration 10400\t train mse: 1.087E-03\t\n",
      "iteration 10500\t train mse: 8.847E-04\t\n",
      "iteration 10600\t train mse: 9.618E-04\t\n",
      "iteration 10700\t train mse: 9.171E-04\t\n",
      "iteration 10800\t train mse: 1.107E-03\t\n",
      "iteration 10900\t train mse: 9.275E-04\t\n",
      "iteration 11000\t train mse: 9.980E-04\t\n",
      "iteration 11000\t TEST MSE: 4.419E-03\t TEST MSE(Quantized): 4.814E-03\t\n",
      "iteration 11100\t train mse: 8.861E-04\t\n",
      "iteration 11200\t train mse: 8.758E-04\t\n",
      "iteration 11300\t train mse: 8.425E-04\t\n",
      "iteration 11400\t train mse: 8.891E-04\t\n",
      "iteration 11500\t train mse: 8.373E-04\t\n",
      "iteration 11600\t train mse: 6.737E-04\t\n",
      "iteration 11700\t train mse: 9.457E-04\t\n",
      "iteration 11800\t train mse: 1.109E-03\t\n",
      "iteration 11900\t train mse: 9.244E-04\t\n",
      "iteration 12000\t train mse: 9.783E-04\t\n",
      "iteration 12000\t TEST MSE: 4.410E-03\t TEST MSE(Quantized): 4.805E-03\t\n",
      "iteration 12100\t train mse: 7.938E-04\t\n",
      "iteration 12200\t train mse: 1.072E-03\t\n",
      "iteration 12300\t train mse: 9.620E-04\t\n",
      "iteration 12400\t train mse: 1.083E-03\t\n",
      "iteration 12500\t train mse: 1.031E-03\t\n",
      "iteration 12600\t train mse: 7.998E-04\t\n",
      "iteration 12700\t train mse: 1.063E-03\t\n",
      "iteration 12800\t train mse: 8.933E-04\t\n",
      "iteration 12900\t train mse: 9.067E-04\t\n",
      "iteration 13000\t train mse: 9.760E-04\t\n",
      "iteration 13000\t TEST MSE: 4.416E-03\t TEST MSE(Quantized): 4.811E-03\t\n",
      "iteration 13100\t train mse: 9.725E-04\t\n",
      "iteration 13200\t train mse: 8.087E-04\t\n",
      "iteration 13300\t train mse: 1.043E-03\t\n",
      "iteration 13400\t train mse: 9.925E-04\t\n",
      "iteration 13500\t train mse: 1.119E-03\t\n",
      "iteration 13600\t train mse: 1.028E-03\t\n",
      "iteration 13700\t train mse: 1.144E-03\t\n",
      "iteration 13800\t train mse: 1.145E-03\t\n",
      "iteration 13900\t train mse: 9.955E-04\t\n",
      "iteration 14000\t train mse: 7.898E-04\t\n",
      "iteration 14000\t TEST MSE: 4.418E-03\t TEST MSE(Quantized): 4.813E-03\t\n",
      "iteration 14100\t train mse: 7.735E-04\t\n",
      "iteration 14200\t train mse: 1.029E-03\t\n",
      "iteration 14300\t train mse: 8.740E-04\t\n",
      "iteration 14400\t train mse: 7.712E-04\t\n",
      "iteration 14500\t train mse: 8.648E-04\t\n",
      "iteration 14600\t train mse: 9.458E-04\t\n",
      "iteration 14700\t train mse: 9.509E-04\t\n",
      "iteration 14800\t train mse: 9.566E-04\t\n",
      "iteration 14900\t train mse: 7.883E-04\t\n",
      "iteration 15000\t train mse: 9.869E-04\t\n",
      "iteration 15000\t TEST MSE: 4.424E-03\t TEST MSE(Quantized): 4.819E-03\t\n",
      "iteration 15100\t train mse: 9.681E-04\t\n",
      "iteration 15200\t train mse: 9.594E-04\t\n",
      "iteration 15300\t train mse: 9.066E-04\t\n",
      "iteration 15400\t train mse: 9.083E-04\t\n",
      "iteration 15500\t train mse: 7.826E-04\t\n",
      "iteration 15600\t train mse: 7.817E-04\t\n",
      "iteration 15700\t train mse: 1.098E-03\t\n",
      "iteration 15800\t train mse: 1.002E-03\t\n",
      "iteration 15900\t train mse: 8.276E-04\t\n",
      "iteration 16000\t train mse: 7.823E-04\t\n",
      "iteration 16000\t TEST MSE: 4.424E-03\t TEST MSE(Quantized): 4.818E-03\t\n",
      "iteration 16100\t train mse: 8.182E-04\t\n",
      "iteration 16200\t train mse: 1.185E-03\t\n",
      "iteration 16300\t train mse: 1.113E-03\t\n",
      "iteration 16400\t train mse: 8.696E-04\t\n",
      "iteration 16500\t train mse: 9.285E-04\t\n",
      "iteration 16600\t train mse: 8.370E-04\t\n",
      "iteration 16700\t train mse: 6.582E-04\t\n",
      "iteration 16800\t train mse: 9.068E-04\t\n",
      "iteration 16900\t train mse: 8.293E-04\t\n",
      "iteration 17000\t train mse: 1.155E-03\t\n",
      "iteration 17000\t TEST MSE: 4.424E-03\t TEST MSE(Quantized): 4.818E-03\t\n",
      "iteration 17100\t train mse: 9.581E-04\t\n",
      "iteration 17200\t train mse: 9.293E-04\t\n",
      "iteration 17300\t train mse: 7.667E-04\t\n",
      "iteration 17400\t train mse: 1.109E-03\t\n",
      "iteration 17500\t train mse: 8.441E-04\t\n",
      "iteration 17600\t train mse: 7.371E-04\t\n",
      "iteration 17700\t train mse: 8.533E-04\t\n",
      "iteration 17800\t train mse: 1.129E-03\t\n",
      "iteration 17900\t train mse: 8.557E-04\t\n",
      "iteration 18000\t train mse: 8.608E-04\t\n",
      "iteration 18000\t TEST MSE: 4.426E-03\t TEST MSE(Quantized): 4.821E-03\t\n",
      "iteration 18100\t train mse: 9.198E-04\t\n",
      "iteration 18200\t train mse: 7.665E-04\t\n",
      "iteration 18300\t train mse: 1.034E-03\t\n",
      "iteration 18400\t train mse: 9.633E-04\t\n",
      "iteration 18500\t train mse: 8.536E-04\t\n",
      "iteration 18600\t train mse: 8.444E-04\t\n",
      "iteration 18700\t train mse: 1.055E-03\t\n",
      "iteration 18800\t train mse: 9.166E-04\t\n",
      "iteration 18900\t train mse: 6.444E-04\t\n",
      "iteration 19000\t train mse: 1.013E-03\t\n",
      "iteration 19000\t TEST MSE: 4.426E-03\t TEST MSE(Quantized): 4.820E-03\t\n",
      "iteration 19100\t train mse: 6.313E-04\t\n",
      "iteration 19200\t train mse: 8.452E-04\t\n",
      "iteration 19300\t train mse: 1.002E-03\t\n",
      "iteration 19400\t train mse: 8.902E-04\t\n",
      "iteration 19500\t train mse: 1.046E-03\t\n",
      "iteration 19600\t train mse: 1.068E-03\t\n",
      "iteration 19700\t train mse: 7.269E-04\t\n",
      "iteration 19800\t train mse: 7.750E-04\t\n",
      "iteration 19900\t train mse: 1.141E-03\t\n",
      "iteration 20000\t train mse: 1.098E-03\t\n",
      "iteration 20000\t TEST MSE: 4.435E-03\t TEST MSE(Quantized): 4.829E-03\t\n",
      "Model saved in file: /tmp/cnnx4_test7_lion\n"
     ]
    }
   ],
   "source": [
    "#Code for fine-tuning\n",
    "\n",
    "img = skimage.io.imread('../test_img_old/lena512color.tiff')\n",
    "img_32=img2block(img)\n",
    "\n",
    "tmp=x_tr.copy()\n",
    "x_tr=img_32.copy()\n",
    "idx=np.random.permutation(x_tr.shape[0])\n",
    "x_tr=x_tr[idx,:,:,:]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse(x_tr=img_32,kernels1=[5,7,9,9],kernels2=[7,7],\n",
    "                                     filters1=[128,64,16,8],filters2=[8,3],\n",
    "                                     pool_size=[1,2,2,1,2,2],learning_rate=1e-6,FT=True)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=1000,load=True,\n",
    "                    fname='cifar10_recon6',outname='/tmp/cnnx4_test7',ftname='/tmp/cnnx4_test7_lion')\n",
    "\n",
    "x_tr=tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/cnnx4_test7_lion\n",
      "Model loaded\n",
      "5\n",
      "1th slice\n",
      "2th slice\n",
      "3th slice\n",
      "4th slice\n",
      "5th slice\n"
     ]
    }
   ],
   "source": [
    "#Apply the pre-trained netowrk on another image\n",
    "\n",
    "tfsave ='/tmp/cnnx4_test7_lion'\n",
    "imgpath = '../test_img_old/lion.tiff'\n",
    "outpath='../test_img/lion_recon2_convrealFTpx8.tiff'\n",
    "with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "#with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    '''\n",
    "    var_list=[]\n",
    "    with tf.variable_scope('conv1',reuse=True):\n",
    "        var_list.append ( tf.get_variable('kernel') )\n",
    "    '''\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tfsave)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    img = skimage.io.imread(imgpath)\n",
    "    [w,l,c]=img.shape\n",
    "    img_32=img2block(img)\n",
    "    img_block = np.zeros(img_32.shape)\n",
    "    \n",
    "    n= np.floor(img_32.shape[0]/2000).astype(int)\n",
    "    print(n)\n",
    "    for i in range(0,n):\n",
    "        print(str(i+1)+'th slice')\n",
    "        img_block[i*2000:(i+1)*2000,:,:,:]=sess.run(model_dict['outputs'], \n",
    "                                    feed_dict={model_dict['inputs']:img_32[i*2000:(i+1)*2000,:,:,:]})\n",
    "    img_block[n*2000:,:,:,:]=sess.run(model_dict['outputs'], \n",
    "                                    feed_dict={model_dict['inputs']:img_32[n*2000:,:,:,:]})\n",
    "        \n",
    "    img_recon=block2img(img_block,(w,l))\n",
    "    img_recon = convert2uint8(img_recon*255.)\n",
    "    skimage.io.imsave(outpath,img_recon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
